{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM ok.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ0XB2IjjgBu",
        "colab_type": "code",
        "outputId": "213b97ff-0264-4a87-ade6-0c2e4d811b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYNjkMUojs01",
        "colab_type": "code",
        "outputId": "a6d8229c-3c0f-4e4f-d726-024377bb4d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku\n",
        "import pandas as pd\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6DyRmV8j2C0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f2625cfb-c9ae-4ee9-e00d-fca3ceac1ba0"
      },
      "source": [
        "lagu = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/song_df_indo.csv\")\n",
        "lagu.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>judul</th>\n",
              "      <th>penyanyi</th>\n",
              "      <th>link</th>\n",
              "      <th>lirik</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>A Lotta Love</td>\n",
              "      <td>3 Diva</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/3-diva/a-lot...</td>\n",
              "      <td>(*) Iâ¦ I, I, I, Iâ¦ Need A Lotta Love Youâ...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>A Minor</td>\n",
              "      <td>Kaneshiba</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/kaneshiba/a-...</td>\n",
              "      <td>Dari A minor Pindahnya ke D minor Masuk kunci ...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>A N G</td>\n",
              "      <td>Naff</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/naff/a-n-g/</td>\n",
              "      <td>NAFF - A.N.G Seluruh hati tlah kudatangi Hanya...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>A S A</td>\n",
              "      <td>Arwana</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/arwana/a-s-a/</td>\n",
              "      <td>Dalam malam kucoba mengerti Tentang luka yang ...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>A Tribute To Maia</td>\n",
              "      <td>Tha Law</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/tha-law/a-tr...</td>\n",
              "      <td>Now throw ur hand in the air buat duo Maia Jar...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id  ...                                              lirik lang\n",
              "0           8   9  ...  (*) Iâ¦ I, I, I, Iâ¦ Need A Lotta Love Youâ...   id\n",
              "1          10  11  ...  Dari A minor Pindahnya ke D minor Masuk kunci ...   id\n",
              "2          11  12  ...  NAFF - A.N.G Seluruh hati tlah kudatangi Hanya...   id\n",
              "3          17  18  ...  Dalam malam kucoba mengerti Tentang luka yang ...   id\n",
              "4          20  21  ...  Now throw ur hand in the air buat duo Maia Jar...   id\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3xcETsiMjzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "da310fea-e16f-49a1-9459-4a2aa281b66f"
      },
      "source": [
        "lagu = lagu[lagu.penyanyi==\"Didi Kempot\"]\n",
        "lagu.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>judul</th>\n",
              "      <th>penyanyi</th>\n",
              "      <th>link</th>\n",
              "      <th>lirik</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>Aduh Mana Tahan</td>\n",
              "      <td>Didi Kempot</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/didi-kempot/...</td>\n",
              "      <td>Aduh aduh aduh ruminten, percaya pada diriku, ...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>1000</td>\n",
              "      <td>1001</td>\n",
              "      <td>Ambyar</td>\n",
              "      <td>Didi Kempot</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/didi-kempot/...</td>\n",
              "      <td>Wis kebacut ambyar remuk sing ning ati Opo nge...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>1157</td>\n",
              "      <td>1158</td>\n",
              "      <td>Anggar Bini</td>\n",
              "      <td>Didi Kempot</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/didi-kempot/...</td>\n",
              "      <td>Kudu lilo, yen to aku anglemboro Panyuwunku pu...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1584</td>\n",
              "      <td>1585</td>\n",
              "      <td>Awu Merapi</td>\n",
              "      <td>Didi Kempot</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/didi-kempot/...</td>\n",
              "      <td>Neng ngendi kudu lunga Nggoleki kenya sing tak...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>1852</td>\n",
              "      <td>1853</td>\n",
              "      <td>Bangjo Malioboro</td>\n",
              "      <td>Didi Kempot</td>\n",
              "      <td>https://lirik.kapanlagi.com/artis/didi-kempot/...</td>\n",
              "      <td>Lampu bangjo neng prapatan malioboro.. nganti ...</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0    id  ...                                              lirik lang\n",
              "150          205   206  ...  Aduh aduh aduh ruminten, percaya pada diriku, ...   id\n",
              "757         1000  1001  ...  Wis kebacut ambyar remuk sing ning ati Opo nge...   id\n",
              "878         1157  1158  ...  Kudu lilo, yen to aku anglemboro Panyuwunku pu...   id\n",
              "1196        1584  1585  ...  Neng ngendi kudu lunga Nggoleki kenya sing tak...   id\n",
              "1400        1852  1853  ...  Lampu bangjo neng prapatan malioboro.. nganti ...   id\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzawRASasa9j",
        "colab_type": "code",
        "outputId": "214c0c51-d828-4398-b1e4-7d51d4c6a76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    return txt.lower()\n",
        "\n",
        "corpus = [clean_text(x) for x in list(lagu[\"lirik\"])]\n",
        "corpus[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aduh aduh aduh ruminten percaya pada diriku sumpah mati ku cinta kamu bulan depan aku melamarmu gak lucu abang komar gak salah tu emangnya gampang nglamar kerja dulu dong baru nglamar aduh duh kamu hai abang komar apa gak salah akan mau melamar hanya sama minten ai ai kucinta berat kalau minten tolak aduh duh bisa sekarat aduh bang komar pemuda tampan kerjalah dulu kalau mau pacaran percayalah minten abang tunggu panggilan gajinya selangit aduh duh banyak obyekan aduh aduh aduh bang komar sadarlah jangan menghayal banyak sarjana pengangguran nunggu panggilan sampai ubanan aduh ruminten gadis pujaan apa ruminten cari jutawan bukanya ruminten ay ay mata duitan yang penting abang aduh duh punya kerjaan jikalau cinta telah menyatu pahit empedu terasa madu marilah kita ay ay saling mengikat aku tak mau aduh duh si cinta kilat aduh bang komar kusayang kamu aduh ruminten kucinta kamu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJt2X3jTspev",
        "colab_type": "code",
        "outputId": "0b00e99e-2649-4f66-a36f-b7127b080437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gILFPxQ-s_Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDxa_tHktBh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db57560f-2e44-4b71-da77-53c8f346f45e"
      },
      "source": [
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "#print(inp_sequences[:10])\n",
        "\n",
        "print(total_words)\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.utils as ku"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ntgMvUtKU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19d155d2-d3e5-4313-fd48-43bfe433b274"
      },
      "source": [
        "import numpy as np\n",
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
        "\n",
        "print(max_sequence_len)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJzRVGb4tNK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "655a5aa2-0489-461b-b411-3aecff0e7bc0"
      },
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    \n",
        "    #tambahan\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "print(model.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 251, 10)           20930     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2093)              211393    \n",
            "=================================================================\n",
            "Total params: 286,823\n",
            "Trainable params: 286,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fq6uIbstp0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f7ca32d-5eec-4d8b-9296-e395b27ea2ad"
      },
      "source": [
        "model.fit(predictors, label, epochs=100, batch_size=1024)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 7.6429\n",
            "Epoch 2/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 7.5376\n",
            "Epoch 3/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 6.9252\n",
            "Epoch 4/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 6.7526\n",
            "Epoch 5/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 6.7141\n",
            "Epoch 6/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 6.6987\n",
            "Epoch 7/100\n",
            "8951/8951 [==============================] - 35s 4ms/step - loss: 6.6910\n",
            "Epoch 8/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6892\n",
            "Epoch 9/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6852\n",
            "Epoch 10/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6821\n",
            "Epoch 11/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6779\n",
            "Epoch 12/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6726\n",
            "Epoch 13/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6674\n",
            "Epoch 14/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6603\n",
            "Epoch 15/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6521\n",
            "Epoch 16/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6412\n",
            "Epoch 17/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6297\n",
            "Epoch 18/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.6133\n",
            "Epoch 19/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.5935\n",
            "Epoch 20/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.5667\n",
            "Epoch 21/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.5425\n",
            "Epoch 22/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.5181\n",
            "Epoch 23/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 6.4913\n",
            "Epoch 24/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.4672\n",
            "Epoch 25/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.4441\n",
            "Epoch 26/100\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.4234\n",
            "Epoch 27/100\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.4010\n",
            "Epoch 28/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.3756\n",
            "Epoch 29/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.3482\n",
            "Epoch 30/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.3151\n",
            "Epoch 31/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.2757\n",
            "Epoch 32/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 6.2336\n",
            "Epoch 33/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 6.1884\n",
            "Epoch 34/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.1441\n",
            "Epoch 35/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.1011\n",
            "Epoch 36/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 6.0596\n",
            "Epoch 37/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 6.0202\n",
            "Epoch 38/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.9779\n",
            "Epoch 39/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 5.9342\n",
            "Epoch 40/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.8858\n",
            "Epoch 41/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.8405\n",
            "Epoch 42/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.7936\n",
            "Epoch 43/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.7457\n",
            "Epoch 44/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.6998\n",
            "Epoch 45/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.6455\n",
            "Epoch 46/100\n",
            "8951/8951 [==============================] - 37s 4ms/step - loss: 5.5959\n",
            "Epoch 47/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 5.5488\n",
            "Epoch 48/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.5025\n",
            "Epoch 49/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.4496\n",
            "Epoch 50/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.4026\n",
            "Epoch 51/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.3540\n",
            "Epoch 52/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.3006\n",
            "Epoch 53/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.2649\n",
            "Epoch 54/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.2094\n",
            "Epoch 55/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.1560\n",
            "Epoch 56/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.1110\n",
            "Epoch 57/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 5.0612\n",
            "Epoch 58/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 5.0217\n",
            "Epoch 59/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 4.9667\n",
            "Epoch 60/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.9254\n",
            "Epoch 61/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.8906\n",
            "Epoch 62/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.8434\n",
            "Epoch 63/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.7924\n",
            "Epoch 64/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.8719\n",
            "Epoch 65/100\n",
            "8951/8951 [==============================] - 38s 4ms/step - loss: 4.9476\n",
            "Epoch 66/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.8182\n",
            "Epoch 67/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.7160\n",
            "Epoch 68/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.6586\n",
            "Epoch 69/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.6079\n",
            "Epoch 70/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.5652\n",
            "Epoch 71/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 4.5217\n",
            "Epoch 72/100\n",
            "8951/8951 [==============================] - 31s 4ms/step - loss: 4.4845\n",
            "Epoch 73/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.4446\n",
            "Epoch 74/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.4062\n",
            "Epoch 75/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.3709\n",
            "Epoch 76/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.3333\n",
            "Epoch 77/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 4.2974\n",
            "Epoch 78/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.2602\n",
            "Epoch 79/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.2256\n",
            "Epoch 80/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.1924\n",
            "Epoch 81/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.1571\n",
            "Epoch 82/100\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.1231\n",
            "Epoch 83/100\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.0846\n",
            "Epoch 84/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.0526\n",
            "Epoch 85/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.0178\n",
            "Epoch 86/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.9800\n",
            "Epoch 87/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.9448\n",
            "Epoch 88/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.9088\n",
            "Epoch 89/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.8829\n",
            "Epoch 90/100\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.8467\n",
            "Epoch 91/100\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.8136\n",
            "Epoch 92/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.7853\n",
            "Epoch 93/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.7575\n",
            "Epoch 94/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.7340\n",
            "Epoch 95/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.6962\n",
            "Epoch 96/100\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.6634\n",
            "Epoch 97/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.6309\n",
            "Epoch 98/100\n",
            "8951/8951 [==============================] - 31s 3ms/step - loss: 3.6017\n",
            "Epoch 99/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.5709\n",
            "Epoch 100/100\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 3.5461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f35906aeeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGi0Yh6ItwUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvik9cG1sp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5141f47c-6b8d-4629-ef07-674e21120980"
      },
      "source": [
        "print (generate_text(\"kowe ayu tenan dek\", 25, model, max_sequence_len))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kowe Ayu Tenan Dek Kere Kowe Kere Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye Piye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvsNuM0W1wU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump\n",
        "model.save('model_lagu_dikem_100_epoch.h5')\n",
        "#save the tokenizer\n",
        "dump(tokenizer, open('tokenizer_lagu_dikem_100_epoch.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0udGOlvmio6t",
        "colab_type": "code",
        "outputId": "2eacfbde-49af-4cd5-cb9b-ba9b13dbf131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#tes 1000 epoch\n",
        "model2 = create_model(max_sequence_len, total_words)\n",
        "print(model2.summary())\n",
        "model2.fit(predictors, label, epochs=1000, batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 251, 10)           20930     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2093)              211393    \n",
            "=================================================================\n",
            "Total params: 286,823\n",
            "Trainable params: 286,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8951/8951 [==============================] - 35s 4ms/step - loss: 7.6422\n",
            "Epoch 2/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 7.5216\n",
            "Epoch 3/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.9374\n",
            "Epoch 4/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.7541\n",
            "Epoch 5/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.7088\n",
            "Epoch 6/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6986\n",
            "Epoch 7/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6903\n",
            "Epoch 8/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6879\n",
            "Epoch 9/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6852\n",
            "Epoch 10/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6816\n",
            "Epoch 11/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.6778\n",
            "Epoch 12/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6732\n",
            "Epoch 13/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.6675\n",
            "Epoch 14/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.6600\n",
            "Epoch 15/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6502\n",
            "Epoch 16/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6389\n",
            "Epoch 17/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6239\n",
            "Epoch 18/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.6042\n",
            "Epoch 19/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.5808\n",
            "Epoch 20/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.5529\n",
            "Epoch 21/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.5300\n",
            "Epoch 22/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.5074\n",
            "Epoch 23/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.4832\n",
            "Epoch 24/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.4582\n",
            "Epoch 25/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.4300\n",
            "Epoch 26/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.4012\n",
            "Epoch 27/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.3638\n",
            "Epoch 28/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.3283\n",
            "Epoch 29/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.2898\n",
            "Epoch 30/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.2468\n",
            "Epoch 31/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.2102\n",
            "Epoch 32/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.1735\n",
            "Epoch 33/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.1382\n",
            "Epoch 34/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 6.1052\n",
            "Epoch 35/1000\n",
            "8951/8951 [==============================] - 38s 4ms/step - loss: 6.0677\n",
            "Epoch 36/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 6.0265\n",
            "Epoch 37/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.9841\n",
            "Epoch 38/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.9376\n",
            "Epoch 39/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.8917\n",
            "Epoch 40/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.8422\n",
            "Epoch 41/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.7925\n",
            "Epoch 42/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.7410\n",
            "Epoch 43/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.6921\n",
            "Epoch 44/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.6445\n",
            "Epoch 45/1000\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.5967\n",
            "Epoch 46/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.5499\n",
            "Epoch 47/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.4957\n",
            "Epoch 48/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.4472\n",
            "Epoch 49/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.3945\n",
            "Epoch 50/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.3490\n",
            "Epoch 51/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.2981\n",
            "Epoch 52/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.2618\n",
            "Epoch 53/1000\n",
            "8951/8951 [==============================] - 40s 5ms/step - loss: 5.2184\n",
            "Epoch 54/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.1729\n",
            "Epoch 55/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.1313\n",
            "Epoch 56/1000\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.0940\n",
            "Epoch 57/1000\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 5.0534\n",
            "Epoch 58/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 5.0192\n",
            "Epoch 59/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.9826\n",
            "Epoch 60/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.9478\n",
            "Epoch 61/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.9093\n",
            "Epoch 62/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.8711\n",
            "Epoch 63/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.8427\n",
            "Epoch 64/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.7974\n",
            "Epoch 65/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.7545\n",
            "Epoch 66/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.7188\n",
            "Epoch 67/1000\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 4.6870\n",
            "Epoch 68/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.6464\n",
            "Epoch 69/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.6111\n",
            "Epoch 70/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.5768\n",
            "Epoch 71/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.5442\n",
            "Epoch 72/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.5132\n",
            "Epoch 73/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.4865\n",
            "Epoch 74/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.4454\n",
            "Epoch 75/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.4154\n",
            "Epoch 76/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.3822\n",
            "Epoch 77/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.3567\n",
            "Epoch 78/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.3379\n",
            "Epoch 79/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.3689\n",
            "Epoch 80/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.3199\n",
            "Epoch 81/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.2764\n",
            "Epoch 82/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.2166\n",
            "Epoch 83/1000\n",
            "8951/8951 [==============================] - 35s 4ms/step - loss: 4.1688\n",
            "Epoch 84/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.1335\n",
            "Epoch 85/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 4.1005\n",
            "Epoch 86/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.0611\n",
            "Epoch 87/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 4.0259\n",
            "Epoch 88/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.9931\n",
            "Epoch 89/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.9581\n",
            "Epoch 90/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.9235\n",
            "Epoch 91/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.8816\n",
            "Epoch 92/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.8533\n",
            "Epoch 93/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.8149\n",
            "Epoch 94/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.7802\n",
            "Epoch 95/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.7440\n",
            "Epoch 96/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.7097\n",
            "Epoch 97/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.6764\n",
            "Epoch 98/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.6388\n",
            "Epoch 99/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.6074\n",
            "Epoch 100/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.5665\n",
            "Epoch 101/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.5343\n",
            "Epoch 102/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.5036\n",
            "Epoch 103/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.4711\n",
            "Epoch 104/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.4370\n",
            "Epoch 105/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.4086\n",
            "Epoch 106/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.3724\n",
            "Epoch 107/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.3417\n",
            "Epoch 108/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.3169\n",
            "Epoch 109/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.2828\n",
            "Epoch 110/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.2534\n",
            "Epoch 111/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.2237\n",
            "Epoch 112/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.1991\n",
            "Epoch 113/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.1772\n",
            "Epoch 114/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.1458\n",
            "Epoch 115/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 3.1119\n",
            "Epoch 116/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.0863\n",
            "Epoch 117/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.0589\n",
            "Epoch 118/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.0214\n",
            "Epoch 119/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.0034\n",
            "Epoch 120/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 3.0020\n",
            "Epoch 121/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.9591\n",
            "Epoch 122/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.9294\n",
            "Epoch 123/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.9081\n",
            "Epoch 124/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.8869\n",
            "Epoch 125/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.8618\n",
            "Epoch 126/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.8349\n",
            "Epoch 127/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.8154\n",
            "Epoch 128/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.7887\n",
            "Epoch 129/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.7765\n",
            "Epoch 130/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.7568\n",
            "Epoch 131/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.7294\n",
            "Epoch 132/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.7026\n",
            "Epoch 133/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.6788\n",
            "Epoch 134/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.6575\n",
            "Epoch 135/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.6348\n",
            "Epoch 136/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.6186\n",
            "Epoch 137/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.6030\n",
            "Epoch 138/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.5745\n",
            "Epoch 139/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.5613\n",
            "Epoch 140/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.5414\n",
            "Epoch 141/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.5248\n",
            "Epoch 142/1000\n",
            "8951/8951 [==============================] - 38s 4ms/step - loss: 2.5093\n",
            "Epoch 143/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.4930\n",
            "Epoch 144/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.4772\n",
            "Epoch 145/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.4517\n",
            "Epoch 146/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.4325\n",
            "Epoch 147/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.4201\n",
            "Epoch 148/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.4056\n",
            "Epoch 149/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3856\n",
            "Epoch 150/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3689\n",
            "Epoch 151/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3594\n",
            "Epoch 152/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3398\n",
            "Epoch 153/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3220\n",
            "Epoch 154/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3378\n",
            "Epoch 155/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.3144\n",
            "Epoch 156/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 2.2865\n",
            "Epoch 157/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.2615\n",
            "Epoch 158/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.2519\n",
            "Epoch 159/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.2294\n",
            "Epoch 160/1000\n",
            "8951/8951 [==============================] - 41s 5ms/step - loss: 2.2235\n",
            "Epoch 161/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.2063\n",
            "Epoch 162/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.1925\n",
            "Epoch 163/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.1709\n",
            "Epoch 164/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.1621\n",
            "Epoch 165/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.1519\n",
            "Epoch 166/1000\n",
            "8951/8951 [==============================] - 32s 4ms/step - loss: 2.1358\n",
            "Epoch 167/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.1206\n",
            "Epoch 168/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.1089\n",
            "Epoch 169/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0989\n",
            "Epoch 170/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0890\n",
            "Epoch 171/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0700\n",
            "Epoch 172/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0545\n",
            "Epoch 173/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0506\n",
            "Epoch 174/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0362\n",
            "Epoch 175/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0234\n",
            "Epoch 176/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 2.0052\n",
            "Epoch 177/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 1.9981\n",
            "Epoch 178/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 1.9851\n",
            "Epoch 179/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 1.9732\n",
            "Epoch 180/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 1.9660\n",
            "Epoch 181/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 1.9517\n",
            "Epoch 182/1000\n",
            "8951/8951 [==============================] - 33s 4ms/step - loss: 1.9411\n",
            "Epoch 183/1000\n",
            "8951/8951 [==============================] - 34s 4ms/step - loss: 1.9276\n",
            "Epoch 184/1000\n",
            "3072/8951 [=========>....................] - ETA: 21s - loss: 1.8637"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEnijpOFlhCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}